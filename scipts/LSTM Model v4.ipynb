{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>FINAL DATA PREPROCESSING & MODEL TRAINING</h2>\n",
    "\n",
    "Script ini digunakan untuk mempreprocess data menjadi data final yang dapat digunakan untuk training model, dan training model LSTM itu sendiri. Secara umum, script ini meliputi:\n",
    "<h4>Data Preprocessing</h4>\n",
    "- Padding & Truncating data, pada dasarnya memastikan seluruh trj_id memiliki jumlah data yang sama, yakni 20 data, dengan menambahkan data yang kurang dengan 0 dan memotong data yang kelebihan dan mengambil 20 data paling belakang.\n",
    "- Membagi data menjadi X (koordinat, keceptan, dll yang dimasukkan ke model untuk melatih model) dan y (koordinat yang benar untuk dibandingkan dengan koordinat hasil prediksi model). y akan diambil dari koordinat terakhir tiap trajectory.\n",
    "- Membagi data menjadi training data dan testing data, dengan pembagian 90%/10%.\n",
    "<br/>\n",
    "<h4>Model Training</h4>\n",
    "- Mendefinisikan dan melatih model LSTM berdasarkan data yang telah siap.\n",
    "- Arsitektur, epoch, loss, optimizer, dan dll dapat dengan bebas diubah-ubah untuk mencoba model lain.\n",
    "<br/>\n",
    "Jika ingin melihat performa model pertama yang telah saya latih, maka model itu sudah disave dalam folder models dengan nama model_v1.keras. Model dapat ditest menggunakan script Model Test.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tensorboard\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          rawlat      rawlng      speed     bearing  hour_of_day  day_of_week\n",
      "trj_id                                                                       \n",
      "1      -6.198042  106.769008   4.322800  179.920000           14            3\n",
      "1      -6.200972  106.769202   8.014167  173.233333           14            3\n",
      "1      -6.205394  106.769768  10.116136  171.477273           14            3\n",
      "1      -6.210496  106.771217   9.307667  156.683333           14            3\n",
      "1      -6.214969  106.773830  10.103333  139.777778           14            3\n",
      "...          ...         ...        ...         ...          ...          ...\n",
      "9999   -6.184174  106.843572   3.187241  229.396552            4            6\n",
      "9999   -6.182703  106.842868   2.684167  277.566667            4            6\n",
      "9999   -6.180504  106.842337   5.244333  326.850000            4            6\n",
      "9999   -6.178920  106.841976   0.843966   83.672414            4            6\n",
      "9999   -6.178846  106.841960   0.000000    0.000000            4            6\n",
      "\n",
      "[1223918 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "## Read data from csv\n",
    "resampled_data = pd.read_csv('../clean_data.csv', index_col='trj_id').drop('Unnamed: 1', axis=1)\n",
    "print(resampled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          rawlat      rawlng      speed     bearing  hour_of_day  day_of_week\n",
      "trj_id                                                                       \n",
      "10003  -6.174612  106.897354   4.663077  283.730769           10            4\n",
      "10003  -6.175318  106.895763   4.550667  219.833333           10            4\n",
      "10003  -6.175477  106.893716   7.932833  260.850000           10            4\n",
      "10003  -6.172101  106.888970  11.278000  302.183333           10            4\n",
      "10003  -6.168788  106.883564  12.240500  300.483333           10            4\n",
      "...          ...         ...        ...         ...          ...          ...\n",
      "9999   -6.184174  106.843572   3.187241  229.396552            4            6\n",
      "9999   -6.182703  106.842868   2.684167  277.566667            4            6\n",
      "9999   -6.180504  106.842337   5.244333  326.850000            4            6\n",
      "9999   -6.178920  106.841976   0.843966   83.672414            4            6\n",
      "9999   -6.178846  106.841960   0.000000    0.000000            4            6\n",
      "\n",
      "[369135 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Optimize Dataset Further\n",
    "counts = resampled_data.groupby(level='trj_id').size()\n",
    "filtered_df = resampled_data[resampled_data.index.get_level_values('trj_id').isin(counts[counts >= 30].index)]\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad and truncate the timestamps in the dataframe\n",
    "# Ini buat kita samain input modelnya, gw potong timestampnya jadi pasti ada 60 timestamp per sample. Kalo lebih dipotong, kalo kurang ditambahin 0 di depannya\n",
    "# Pad value None --> pake koordinat pertama\n",
    "\n",
    "def pad_truncate_dataframe(df, max_len, padding='pre', truncating='post', pad_value=None):\n",
    "  # Split the dataframe by samples (first level of multi-index)\n",
    "  samples = df.groupby(level=0)\n",
    "\n",
    "  # Define a function to pad/truncate a single sample\n",
    "  def pad_truncate_sample(sample):\n",
    "    # Extract the values from a single sample\n",
    "    values = sample.values\n",
    "    first_element = values[0]\n",
    "    first_element[2] = 0\n",
    "    first_element[3] = 0\n",
    "\n",
    "    # Pad/truncate automatically using pad_sequences\n",
    "    if pad_value == None:\n",
    "      padded_truncated = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "          [values], maxlen=max_len, padding=padding, truncating=truncating, value=first_element, dtype='float64'\n",
    "      )[0]\n",
    "    else:\n",
    "      padded_truncated = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "          [values], maxlen=max_len, padding=padding, truncating=truncating, value=pad_value, dtype='float64'\n",
    "      )[0]\n",
    "\n",
    "    # Convert back to pandas dataframe\n",
    "    return pd.DataFrame(padded_truncated, columns=sample.columns)\n",
    "\n",
    "  # Apply the function to each sample and recreate the multi-index dataframe\n",
    "  padded_df = samples.apply(pad_truncate_sample)\n",
    "  return padded_df\n",
    "\n",
    "df_new = pad_truncate_dataframe(filtered_df, 61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7935, 61, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Convert the multi index dataframe to a numpy 3D array for better integration to TensorFlow (samples, timesteps, features)\n",
    "numpy_data = df_new.to_xarray().to_array().to_numpy()\n",
    "numpy_data = np.transpose(numpy_data, (1, 2, 0))\n",
    "numpy_data.shape # Should be (55994, 21, 6) if 55994 samples, 21 timesteps, and 6 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_steps = 10\n",
    "\n",
    "## Split the data to x (feature values) and y (target values)\n",
    "simple_data = numpy_data[:, :, [0, 1, 4, 5]]\n",
    "x_data = simple_data[:, :-output_steps, :]\n",
    "y_data = simple_data[:, -output_steps:, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to train and test splits (train to train the model, test to test the model on new data after trained)\n",
    "test_size = 0.1\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define normalization layer\n",
    "normalize_layer = tf.keras.layers.Normalization(axis=-1)\n",
    "normalize_layer.adapt(simple_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get Mean and Variance of Normalization layer to use for normalizing y and denormalizing later\n",
    "normalize_weights = normalize_layer.get_weights()\n",
    "\n",
    "mean_variance = np.array([normalize_weights[0][0:2], normalize_weights[1][0:2]])\n",
    "\n",
    "np.save('../mean_variance_E.npy', mean_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.8586281   0.4043706 ]\n",
      "  [ 0.89817     0.41383514]\n",
      "  [ 0.9049063   0.39166653]\n",
      "  ...\n",
      "  [ 0.8360101   0.20294754]\n",
      "  [ 0.8344211   0.18109654]\n",
      "  [ 0.83275944  0.16108763]]\n",
      "\n",
      " [[-0.87570155  0.73086524]\n",
      "  [-0.87653023  0.7469994 ]\n",
      "  [-0.88981056  0.7602752 ]\n",
      "  ...\n",
      "  [-1.02762     0.86317813]\n",
      "  [-1.0585887   0.91437554]\n",
      "  [-1.0791308   0.95623547]]\n",
      "\n",
      " [[ 1.2726755  -0.34815508]\n",
      "  [ 1.2793862  -0.38150325]\n",
      "  [ 1.2827735  -0.38918924]\n",
      "  ...\n",
      "  [ 1.3560139  -0.42260095]\n",
      "  [ 1.3576713  -0.4222198 ]\n",
      "  [ 1.358658   -0.42202926]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.76683635 -0.12329301]\n",
      "  [ 0.7718298  -0.10900094]\n",
      "  [ 0.7717401  -0.09680503]\n",
      "  ...\n",
      "  [ 0.7604418  -0.02585279]\n",
      "  [ 0.7620607   0.0040653 ]\n",
      "  [ 0.764       0.02750432]]\n",
      "\n",
      " [[ 1.3024185   0.28298318]\n",
      "  [ 1.2806847   0.20955366]\n",
      "  [ 1.2533723   0.11833843]\n",
      "  ...\n",
      "  [ 1.1927032  -0.16508941]\n",
      "  [ 1.2173374  -0.15498967]\n",
      "  [ 1.2078502  -0.1457157 ]]\n",
      "\n",
      " [[ 0.534369   -1.664551  ]\n",
      "  [ 0.6042134  -1.6646144 ]\n",
      "  [ 0.6530973  -1.6383171 ]\n",
      "  ...\n",
      "  [ 0.8275182  -1.5249332 ]\n",
      "  [ 0.8345193  -1.486821  ]\n",
      "  [ 0.84213126 -1.4424838 ]]], shape=(7141, 10, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## Normalize y\n",
    "normalize_y = tf.keras.layers.Normalization(mean=mean_variance[0], variance=mean_variance[1])\n",
    "\n",
    "y_train = normalize_y(y_train)\n",
    "y_test = normalize_y(y_test)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save test data for model testing\n",
    "np.save('../x_test_E.npy', x_test)\n",
    "np.save('../y_test_E.npy', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\adrie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:74: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ normalization (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">68,096</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,580</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ normalization (\u001b[38;5;33mNormalization\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │             \u001b[38;5;34m9\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m68,096\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │         \u001b[38;5;34m2,580\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m2\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">202,269</span> (790.12 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m202,269\u001b[0m (790.12 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">202,260</span> (790.08 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m202,260\u001b[0m (790.08 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> (40.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m9\u001b[0m (40.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_features = 4\n",
    "num_targets = 2\n",
    "\n",
    "# Clear any previous models\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=(50, num_features)))\n",
    "model.add(normalize_layer)\n",
    "model.add(tf.keras.layers.LSTM(128, return_sequences=True))\n",
    "model.add(tf.keras.layers.LSTM(128))\n",
    "model.add(tf.keras.layers.Dense(num_targets * output_steps))\n",
    "model.add(tf.keras.layers.Reshape([output_steps, num_targets]))\n",
    "\n",
    "\n",
    "# Define optimizer\n",
    "lr = 1e-3\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "model.compile(loss='huber', optimizer=opt, metrics=['mae', 'mse', 'accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define LR scheduling (optional if want to use or not)\n",
    "start_lr = lr\n",
    "min_lr = 0.00001\n",
    "max_lr = 0.001\n",
    "rampup_epochs = 0\n",
    "sustain_epochs = 0\n",
    "exp_decay = 0.0\n",
    "\n",
    "# Define the scheduling function\n",
    "def schedule(epoch):\n",
    "  def lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay):\n",
    "    if epoch < rampup_epochs:\n",
    "      lr = (max_lr - start_lr)/rampup_epochs * epoch + start_lr\n",
    "    elif epoch < rampup_epochs + sustain_epochs:\n",
    "      lr = max_lr\n",
    "    else:\n",
    "      lr = (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr\n",
    "    return lr\n",
    "  return lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 78ms/step - accuracy: 0.7958 - loss: 0.2678 - mae: 0.5761 - mse: 0.6616 - val_accuracy: 0.9336 - val_loss: 0.0481 - val_mae: 0.2315 - val_mse: 0.0970\n",
      "Epoch 2/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 70ms/step - accuracy: 0.9370 - loss: 0.0444 - mae: 0.2119 - mse: 0.0952 - val_accuracy: 0.9516 - val_loss: 0.0251 - val_mae: 0.1617 - val_mse: 0.0503\n",
      "Epoch 3/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 75ms/step - accuracy: 0.9500 - loss: 0.0262 - mae: 0.1580 - mse: 0.0559 - val_accuracy: 0.9538 - val_loss: 0.0205 - val_mae: 0.1463 - val_mse: 0.0410\n",
      "Epoch 4/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 67ms/step - accuracy: 0.9551 - loss: 0.0214 - mae: 0.1430 - mse: 0.0441 - val_accuracy: 0.9596 - val_loss: 0.0183 - val_mae: 0.1370 - val_mse: 0.0367\n",
      "Epoch 5/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 69ms/step - accuracy: 0.9614 - loss: 0.0184 - mae: 0.1337 - mse: 0.0372 - val_accuracy: 0.9640 - val_loss: 0.0161 - val_mae: 0.1302 - val_mse: 0.0322\n",
      "Epoch 6/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 72ms/step - accuracy: 0.9629 - loss: 0.0159 - mae: 0.1265 - mse: 0.0318 - val_accuracy: 0.9651 - val_loss: 0.0147 - val_mae: 0.1217 - val_mse: 0.0294\n",
      "Epoch 7/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 70ms/step - accuracy: 0.9611 - loss: 0.0146 - mae: 0.1208 - mse: 0.0293 - val_accuracy: 0.9647 - val_loss: 0.0136 - val_mae: 0.1176 - val_mse: 0.0273\n",
      "Epoch 8/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 68ms/step - accuracy: 0.9640 - loss: 0.0132 - mae: 0.1152 - mse: 0.0265 - val_accuracy: 0.9671 - val_loss: 0.0127 - val_mae: 0.1151 - val_mse: 0.0255\n",
      "Epoch 9/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 68ms/step - accuracy: 0.9660 - loss: 0.0124 - mae: 0.1112 - mse: 0.0249 - val_accuracy: 0.9668 - val_loss: 0.0122 - val_mae: 0.1095 - val_mse: 0.0244\n",
      "Epoch 10/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 67ms/step - accuracy: 0.9648 - loss: 0.0115 - mae: 0.1062 - mse: 0.0229 - val_accuracy: 0.9679 - val_loss: 0.0114 - val_mae: 0.1076 - val_mse: 0.0228\n",
      "Epoch 11/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 66ms/step - accuracy: 0.9682 - loss: 0.0103 - mae: 0.1009 - mse: 0.0205 - val_accuracy: 0.9683 - val_loss: 0.0103 - val_mae: 0.1017 - val_mse: 0.0207\n",
      "Epoch 12/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 65ms/step - accuracy: 0.9710 - loss: 0.0098 - mae: 0.0985 - mse: 0.0196 - val_accuracy: 0.9715 - val_loss: 0.0094 - val_mae: 0.0965 - val_mse: 0.0188\n",
      "Epoch 13/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9733 - loss: 0.0093 - mae: 0.0955 - mse: 0.0186 - val_accuracy: 0.9738 - val_loss: 0.0091 - val_mae: 0.0951 - val_mse: 0.0182\n",
      "Epoch 14/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.9739 - loss: 0.0084 - mae: 0.0910 - mse: 0.0168 - val_accuracy: 0.9744 - val_loss: 0.0084 - val_mae: 0.0900 - val_mse: 0.0167\n",
      "Epoch 15/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.9725 - loss: 0.0083 - mae: 0.0896 - mse: 0.0166 - val_accuracy: 0.9737 - val_loss: 0.0081 - val_mae: 0.0885 - val_mse: 0.0162\n",
      "Epoch 16/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.9747 - loss: 0.0079 - mae: 0.0872 - mse: 0.0157 - val_accuracy: 0.9758 - val_loss: 0.0077 - val_mae: 0.0870 - val_mse: 0.0153\n",
      "Epoch 17/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 56ms/step - accuracy: 0.9731 - loss: 0.0076 - mae: 0.0859 - mse: 0.0153 - val_accuracy: 0.9736 - val_loss: 0.0078 - val_mae: 0.0875 - val_mse: 0.0156\n",
      "Epoch 18/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9725 - loss: 0.0078 - mae: 0.0857 - mse: 0.0155 - val_accuracy: 0.9763 - val_loss: 0.0070 - val_mae: 0.0822 - val_mse: 0.0140\n",
      "Epoch 19/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9732 - loss: 0.0072 - mae: 0.0835 - mse: 0.0144 - val_accuracy: 0.9777 - val_loss: 0.0068 - val_mae: 0.0821 - val_mse: 0.0135\n",
      "Epoch 20/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9733 - loss: 0.0072 - mae: 0.0836 - mse: 0.0143 - val_accuracy: 0.9793 - val_loss: 0.0071 - val_mae: 0.0827 - val_mse: 0.0141\n",
      "Epoch 21/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 56ms/step - accuracy: 0.9751 - loss: 0.0071 - mae: 0.0828 - mse: 0.0141 - val_accuracy: 0.9736 - val_loss: 0.0068 - val_mae: 0.0823 - val_mse: 0.0136\n",
      "Epoch 22/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9746 - loss: 0.0070 - mae: 0.0822 - mse: 0.0141 - val_accuracy: 0.9761 - val_loss: 0.0065 - val_mae: 0.0796 - val_mse: 0.0129\n",
      "Epoch 23/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 56ms/step - accuracy: 0.9738 - loss: 0.0068 - mae: 0.0811 - mse: 0.0135 - val_accuracy: 0.9805 - val_loss: 0.0064 - val_mae: 0.0786 - val_mse: 0.0129\n",
      "Epoch 24/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.9747 - loss: 0.0067 - mae: 0.0801 - mse: 0.0135 - val_accuracy: 0.9790 - val_loss: 0.0062 - val_mae: 0.0770 - val_mse: 0.0123\n",
      "Epoch 25/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 65ms/step - accuracy: 0.9754 - loss: 0.0063 - mae: 0.0774 - mse: 0.0126 - val_accuracy: 0.9787 - val_loss: 0.0062 - val_mae: 0.0781 - val_mse: 0.0124\n",
      "Epoch 26/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 72ms/step - accuracy: 0.9753 - loss: 0.0064 - mae: 0.0782 - mse: 0.0129 - val_accuracy: 0.9782 - val_loss: 0.0061 - val_mae: 0.0782 - val_mse: 0.0122\n",
      "Epoch 27/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 71ms/step - accuracy: 0.9743 - loss: 0.0064 - mae: 0.0780 - mse: 0.0128 - val_accuracy: 0.9798 - val_loss: 0.0063 - val_mae: 0.0789 - val_mse: 0.0125\n",
      "Epoch 28/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 70ms/step - accuracy: 0.9745 - loss: 0.0063 - mae: 0.0768 - mse: 0.0125 - val_accuracy: 0.9810 - val_loss: 0.0060 - val_mae: 0.0759 - val_mse: 0.0119\n",
      "Epoch 29/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 69ms/step - accuracy: 0.9766 - loss: 0.0064 - mae: 0.0769 - mse: 0.0127 - val_accuracy: 0.9802 - val_loss: 0.0056 - val_mae: 0.0735 - val_mse: 0.0112\n",
      "Epoch 30/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 69ms/step - accuracy: 0.9783 - loss: 0.0060 - mae: 0.0746 - mse: 0.0119 - val_accuracy: 0.9759 - val_loss: 0.0062 - val_mae: 0.0778 - val_mse: 0.0123\n",
      "Epoch 31/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 69ms/step - accuracy: 0.9776 - loss: 0.0061 - mae: 0.0758 - mse: 0.0121 - val_accuracy: 0.9802 - val_loss: 0.0057 - val_mae: 0.0747 - val_mse: 0.0114\n",
      "Epoch 32/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 70ms/step - accuracy: 0.9776 - loss: 0.0058 - mae: 0.0736 - mse: 0.0116 - val_accuracy: 0.9801 - val_loss: 0.0055 - val_mae: 0.0729 - val_mse: 0.0110\n",
      "Epoch 33/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 71ms/step - accuracy: 0.9768 - loss: 0.0059 - mae: 0.0736 - mse: 0.0117 - val_accuracy: 0.9805 - val_loss: 0.0054 - val_mae: 0.0720 - val_mse: 0.0108\n",
      "Epoch 34/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 67ms/step - accuracy: 0.9790 - loss: 0.0059 - mae: 0.0743 - mse: 0.0117 - val_accuracy: 0.9802 - val_loss: 0.0057 - val_mae: 0.0742 - val_mse: 0.0115\n",
      "Epoch 35/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 68ms/step - accuracy: 0.9758 - loss: 0.0059 - mae: 0.0745 - mse: 0.0119 - val_accuracy: 0.9810 - val_loss: 0.0056 - val_mae: 0.0743 - val_mse: 0.0112\n",
      "Epoch 36/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 67ms/step - accuracy: 0.9793 - loss: 0.0058 - mae: 0.0735 - mse: 0.0117 - val_accuracy: 0.9792 - val_loss: 0.0055 - val_mae: 0.0724 - val_mse: 0.0109\n",
      "Epoch 37/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 66ms/step - accuracy: 0.9762 - loss: 0.0056 - mae: 0.0720 - mse: 0.0111 - val_accuracy: 0.9815 - val_loss: 0.0057 - val_mae: 0.0757 - val_mse: 0.0115\n",
      "Epoch 38/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9783 - loss: 0.0058 - mae: 0.0741 - mse: 0.0115 - val_accuracy: 0.9771 - val_loss: 0.0058 - val_mae: 0.0747 - val_mse: 0.0116\n",
      "Epoch 39/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9765 - loss: 0.0056 - mae: 0.0723 - mse: 0.0112 - val_accuracy: 0.9812 - val_loss: 0.0052 - val_mae: 0.0695 - val_mse: 0.0103\n",
      "Epoch 40/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9786 - loss: 0.0053 - mae: 0.0707 - mse: 0.0107 - val_accuracy: 0.9814 - val_loss: 0.0052 - val_mae: 0.0706 - val_mse: 0.0104\n",
      "Epoch 41/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9794 - loss: 0.0054 - mae: 0.0705 - mse: 0.0108 - val_accuracy: 0.9807 - val_loss: 0.0052 - val_mae: 0.0706 - val_mse: 0.0105\n",
      "Epoch 42/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.9764 - loss: 0.0052 - mae: 0.0697 - mse: 0.0105 - val_accuracy: 0.9753 - val_loss: 0.0062 - val_mae: 0.0797 - val_mse: 0.0123\n",
      "Epoch 43/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9753 - loss: 0.0054 - mae: 0.0710 - mse: 0.0109 - val_accuracy: 0.9811 - val_loss: 0.0051 - val_mae: 0.0692 - val_mse: 0.0103\n",
      "Epoch 44/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9776 - loss: 0.0052 - mae: 0.0694 - mse: 0.0104 - val_accuracy: 0.9814 - val_loss: 0.0053 - val_mae: 0.0722 - val_mse: 0.0105\n",
      "Epoch 45/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9789 - loss: 0.0052 - mae: 0.0696 - mse: 0.0104 - val_accuracy: 0.9816 - val_loss: 0.0050 - val_mae: 0.0676 - val_mse: 0.0100\n",
      "Epoch 46/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9787 - loss: 0.0052 - mae: 0.0690 - mse: 0.0103 - val_accuracy: 0.9812 - val_loss: 0.0052 - val_mae: 0.0707 - val_mse: 0.0105\n",
      "Epoch 47/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9799 - loss: 0.0051 - mae: 0.0691 - mse: 0.0102 - val_accuracy: 0.9809 - val_loss: 0.0054 - val_mae: 0.0742 - val_mse: 0.0108\n",
      "Epoch 48/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9773 - loss: 0.0053 - mae: 0.0706 - mse: 0.0106 - val_accuracy: 0.9811 - val_loss: 0.0050 - val_mae: 0.0684 - val_mse: 0.0099\n",
      "Epoch 49/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.9789 - loss: 0.0051 - mae: 0.0690 - mse: 0.0101 - val_accuracy: 0.9817 - val_loss: 0.0049 - val_mae: 0.0677 - val_mse: 0.0098\n",
      "Epoch 50/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 56ms/step - accuracy: 0.9782 - loss: 0.0051 - mae: 0.0684 - mse: 0.0101 - val_accuracy: 0.9810 - val_loss: 0.0050 - val_mae: 0.0683 - val_mse: 0.0101\n",
      "Epoch 51/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.9778 - loss: 0.0051 - mae: 0.0689 - mse: 0.0102 - val_accuracy: 0.9814 - val_loss: 0.0050 - val_mae: 0.0677 - val_mse: 0.0099\n",
      "Epoch 52/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9785 - loss: 0.0049 - mae: 0.0673 - mse: 0.0099 - val_accuracy: 0.9815 - val_loss: 0.0050 - val_mae: 0.0687 - val_mse: 0.0101\n",
      "Epoch 53/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9785 - loss: 0.0048 - mae: 0.0666 - mse: 0.0096 - val_accuracy: 0.9802 - val_loss: 0.0048 - val_mae: 0.0676 - val_mse: 0.0097\n",
      "Epoch 54/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9796 - loss: 0.0050 - mae: 0.0680 - mse: 0.0099 - val_accuracy: 0.9806 - val_loss: 0.0048 - val_mae: 0.0678 - val_mse: 0.0096\n",
      "Epoch 55/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9798 - loss: 0.0049 - mae: 0.0668 - mse: 0.0098 - val_accuracy: 0.9821 - val_loss: 0.0047 - val_mae: 0.0658 - val_mse: 0.0094\n",
      "Epoch 56/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9790 - loss: 0.0049 - mae: 0.0676 - mse: 0.0099 - val_accuracy: 0.9822 - val_loss: 0.0049 - val_mae: 0.0674 - val_mse: 0.0098\n",
      "Epoch 57/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.9777 - loss: 0.0050 - mae: 0.0678 - mse: 0.0100 - val_accuracy: 0.9824 - val_loss: 0.0047 - val_mae: 0.0659 - val_mse: 0.0094\n",
      "Epoch 58/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9804 - loss: 0.0049 - mae: 0.0667 - mse: 0.0097 - val_accuracy: 0.9816 - val_loss: 0.0048 - val_mae: 0.0668 - val_mse: 0.0097\n",
      "Epoch 59/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9767 - loss: 0.0049 - mae: 0.0678 - mse: 0.0097 - val_accuracy: 0.9815 - val_loss: 0.0048 - val_mae: 0.0668 - val_mse: 0.0096\n",
      "Epoch 60/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9800 - loss: 0.0047 - mae: 0.0659 - mse: 0.0094 - val_accuracy: 0.9804 - val_loss: 0.0047 - val_mae: 0.0660 - val_mse: 0.0094\n",
      "Epoch 61/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9807 - loss: 0.0046 - mae: 0.0651 - mse: 0.0093 - val_accuracy: 0.9821 - val_loss: 0.0045 - val_mae: 0.0648 - val_mse: 0.0091\n",
      "Epoch 62/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9797 - loss: 0.0047 - mae: 0.0657 - mse: 0.0094 - val_accuracy: 0.9812 - val_loss: 0.0047 - val_mae: 0.0661 - val_mse: 0.0095\n",
      "Epoch 63/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9794 - loss: 0.0047 - mae: 0.0654 - mse: 0.0094 - val_accuracy: 0.9802 - val_loss: 0.0048 - val_mae: 0.0671 - val_mse: 0.0096\n",
      "Epoch 64/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.9775 - loss: 0.0046 - mae: 0.0649 - mse: 0.0092 - val_accuracy: 0.9816 - val_loss: 0.0045 - val_mae: 0.0643 - val_mse: 0.0090\n",
      "Epoch 65/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9787 - loss: 0.0048 - mae: 0.0665 - mse: 0.0095 - val_accuracy: 0.9807 - val_loss: 0.0049 - val_mae: 0.0690 - val_mse: 0.0098\n",
      "Epoch 66/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9799 - loss: 0.0046 - mae: 0.0653 - mse: 0.0093 - val_accuracy: 0.9804 - val_loss: 0.0048 - val_mae: 0.0683 - val_mse: 0.0097\n",
      "Epoch 67/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 56ms/step - accuracy: 0.9807 - loss: 0.0048 - mae: 0.0664 - mse: 0.0095 - val_accuracy: 0.9816 - val_loss: 0.0046 - val_mae: 0.0656 - val_mse: 0.0092\n",
      "Epoch 68/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9784 - loss: 0.0047 - mae: 0.0655 - mse: 0.0095 - val_accuracy: 0.9821 - val_loss: 0.0047 - val_mae: 0.0671 - val_mse: 0.0094\n",
      "Epoch 69/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9804 - loss: 0.0047 - mae: 0.0651 - mse: 0.0093 - val_accuracy: 0.9815 - val_loss: 0.0047 - val_mae: 0.0659 - val_mse: 0.0094\n",
      "Epoch 70/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9819 - loss: 0.0047 - mae: 0.0653 - mse: 0.0093 - val_accuracy: 0.9826 - val_loss: 0.0045 - val_mae: 0.0642 - val_mse: 0.0090\n",
      "Epoch 71/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9799 - loss: 0.0045 - mae: 0.0637 - mse: 0.0091 - val_accuracy: 0.9816 - val_loss: 0.0045 - val_mae: 0.0639 - val_mse: 0.0089\n",
      "Epoch 72/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9802 - loss: 0.0044 - mae: 0.0629 - mse: 0.0087 - val_accuracy: 0.9811 - val_loss: 0.0045 - val_mae: 0.0644 - val_mse: 0.0089\n",
      "Epoch 73/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.9782 - loss: 0.0045 - mae: 0.0643 - mse: 0.0090 - val_accuracy: 0.9825 - val_loss: 0.0045 - val_mae: 0.0647 - val_mse: 0.0090\n",
      "Epoch 74/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9801 - loss: 0.0045 - mae: 0.0641 - mse: 0.0089 - val_accuracy: 0.9825 - val_loss: 0.0046 - val_mae: 0.0661 - val_mse: 0.0092\n",
      "Epoch 75/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9806 - loss: 0.0046 - mae: 0.0646 - mse: 0.0091 - val_accuracy: 0.9815 - val_loss: 0.0045 - val_mae: 0.0649 - val_mse: 0.0089\n",
      "Epoch 76/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9796 - loss: 0.0044 - mae: 0.0637 - mse: 0.0088 - val_accuracy: 0.9840 - val_loss: 0.0043 - val_mae: 0.0635 - val_mse: 0.0086\n",
      "Epoch 77/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9798 - loss: 0.0044 - mae: 0.0629 - mse: 0.0087 - val_accuracy: 0.9830 - val_loss: 0.0043 - val_mae: 0.0632 - val_mse: 0.0087\n",
      "Epoch 78/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9809 - loss: 0.0045 - mae: 0.0636 - mse: 0.0089 - val_accuracy: 0.9838 - val_loss: 0.0044 - val_mae: 0.0642 - val_mse: 0.0088\n",
      "Epoch 79/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9800 - loss: 0.0045 - mae: 0.0641 - mse: 0.0090 - val_accuracy: 0.9827 - val_loss: 0.0045 - val_mae: 0.0643 - val_mse: 0.0091\n",
      "Epoch 80/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9803 - loss: 0.0044 - mae: 0.0631 - mse: 0.0087 - val_accuracy: 0.9830 - val_loss: 0.0045 - val_mae: 0.0652 - val_mse: 0.0090\n",
      "Epoch 81/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9798 - loss: 0.0042 - mae: 0.0624 - mse: 0.0085 - val_accuracy: 0.9829 - val_loss: 0.0045 - val_mae: 0.0658 - val_mse: 0.0091\n",
      "Epoch 82/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9809 - loss: 0.0043 - mae: 0.0625 - mse: 0.0086 - val_accuracy: 0.9834 - val_loss: 0.0044 - val_mae: 0.0632 - val_mse: 0.0088\n",
      "Epoch 83/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9811 - loss: 0.0044 - mae: 0.0628 - mse: 0.0088 - val_accuracy: 0.9821 - val_loss: 0.0044 - val_mae: 0.0632 - val_mse: 0.0087\n",
      "Epoch 84/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.9813 - loss: 0.0043 - mae: 0.0624 - mse: 0.0086 - val_accuracy: 0.9817 - val_loss: 0.0044 - val_mae: 0.0635 - val_mse: 0.0088\n",
      "Epoch 85/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9811 - loss: 0.0043 - mae: 0.0627 - mse: 0.0087 - val_accuracy: 0.9832 - val_loss: 0.0046 - val_mae: 0.0665 - val_mse: 0.0092\n",
      "Epoch 86/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9803 - loss: 0.0043 - mae: 0.0630 - mse: 0.0086 - val_accuracy: 0.9840 - val_loss: 0.0044 - val_mae: 0.0656 - val_mse: 0.0089\n",
      "Epoch 87/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9807 - loss: 0.0041 - mae: 0.0614 - mse: 0.0081 - val_accuracy: 0.9835 - val_loss: 0.0044 - val_mae: 0.0637 - val_mse: 0.0088\n",
      "Epoch 88/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9808 - loss: 0.0043 - mae: 0.0621 - mse: 0.0085 - val_accuracy: 0.9826 - val_loss: 0.0046 - val_mae: 0.0654 - val_mse: 0.0092\n",
      "Epoch 89/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9820 - loss: 0.0041 - mae: 0.0616 - mse: 0.0082 - val_accuracy: 0.9854 - val_loss: 0.0044 - val_mae: 0.0636 - val_mse: 0.0087\n",
      "Epoch 90/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9815 - loss: 0.0042 - mae: 0.0619 - mse: 0.0083 - val_accuracy: 0.9836 - val_loss: 0.0043 - val_mae: 0.0634 - val_mse: 0.0086\n",
      "Epoch 91/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9802 - loss: 0.0043 - mae: 0.0621 - mse: 0.0085 - val_accuracy: 0.9835 - val_loss: 0.0044 - val_mae: 0.0632 - val_mse: 0.0087\n",
      "Epoch 92/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9815 - loss: 0.0043 - mae: 0.0629 - mse: 0.0086 - val_accuracy: 0.9827 - val_loss: 0.0043 - val_mae: 0.0633 - val_mse: 0.0086\n",
      "Epoch 93/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9823 - loss: 0.0042 - mae: 0.0620 - mse: 0.0083 - val_accuracy: 0.9812 - val_loss: 0.0043 - val_mae: 0.0632 - val_mse: 0.0086\n",
      "Epoch 94/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9827 - loss: 0.0041 - mae: 0.0606 - mse: 0.0081 - val_accuracy: 0.9844 - val_loss: 0.0044 - val_mae: 0.0641 - val_mse: 0.0087\n",
      "Epoch 95/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9793 - loss: 0.0042 - mae: 0.0613 - mse: 0.0083 - val_accuracy: 0.9831 - val_loss: 0.0043 - val_mae: 0.0628 - val_mse: 0.0086\n",
      "Epoch 96/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.9817 - loss: 0.0041 - mae: 0.0610 - mse: 0.0081 - val_accuracy: 0.9831 - val_loss: 0.0043 - val_mae: 0.0630 - val_mse: 0.0086\n",
      "Epoch 97/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9827 - loss: 0.0042 - mae: 0.0617 - mse: 0.0083 - val_accuracy: 0.9843 - val_loss: 0.0044 - val_mae: 0.0638 - val_mse: 0.0089\n",
      "Epoch 98/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.9803 - loss: 0.0041 - mae: 0.0607 - mse: 0.0081 - val_accuracy: 0.9845 - val_loss: 0.0042 - val_mae: 0.0617 - val_mse: 0.0084\n",
      "Epoch 99/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9822 - loss: 0.0040 - mae: 0.0605 - mse: 0.0080 - val_accuracy: 0.9854 - val_loss: 0.0043 - val_mae: 0.0630 - val_mse: 0.0086\n",
      "Epoch 100/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 56ms/step - accuracy: 0.9796 - loss: 0.0040 - mae: 0.0604 - mse: 0.0080 - val_accuracy: 0.9841 - val_loss: 0.0043 - val_mae: 0.0624 - val_mse: 0.0085\n",
      "Epoch 101/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9797 - loss: 0.0040 - mae: 0.0602 - mse: 0.0080 - val_accuracy: 0.9844 - val_loss: 0.0045 - val_mae: 0.0646 - val_mse: 0.0090\n",
      "Epoch 102/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9810 - loss: 0.0041 - mae: 0.0615 - mse: 0.0082 - val_accuracy: 0.9832 - val_loss: 0.0045 - val_mae: 0.0650 - val_mse: 0.0090\n",
      "Epoch 103/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9811 - loss: 0.0040 - mae: 0.0603 - mse: 0.0079 - val_accuracy: 0.9829 - val_loss: 0.0042 - val_mae: 0.0619 - val_mse: 0.0085\n",
      "Epoch 104/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 60ms/step - accuracy: 0.9805 - loss: 0.0041 - mae: 0.0611 - mse: 0.0083 - val_accuracy: 0.9817 - val_loss: 0.0045 - val_mae: 0.0648 - val_mse: 0.0089\n",
      "Epoch 105/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 61ms/step - accuracy: 0.9787 - loss: 0.0040 - mae: 0.0608 - mse: 0.0080 - val_accuracy: 0.9844 - val_loss: 0.0042 - val_mae: 0.0619 - val_mse: 0.0084\n",
      "Epoch 106/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9808 - loss: 0.0039 - mae: 0.0592 - mse: 0.0077 - val_accuracy: 0.9840 - val_loss: 0.0042 - val_mae: 0.0624 - val_mse: 0.0085\n",
      "Epoch 107/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9816 - loss: 0.0040 - mae: 0.0609 - mse: 0.0081 - val_accuracy: 0.9835 - val_loss: 0.0042 - val_mae: 0.0624 - val_mse: 0.0085\n",
      "Epoch 108/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9836 - loss: 0.0039 - mae: 0.0599 - mse: 0.0079 - val_accuracy: 0.9821 - val_loss: 0.0048 - val_mae: 0.0678 - val_mse: 0.0095\n",
      "Epoch 109/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9770 - loss: 0.0040 - mae: 0.0608 - mse: 0.0081 - val_accuracy: 0.9831 - val_loss: 0.0044 - val_mae: 0.0643 - val_mse: 0.0089\n",
      "Epoch 110/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.9810 - loss: 0.0039 - mae: 0.0595 - mse: 0.0078 - val_accuracy: 0.9839 - val_loss: 0.0043 - val_mae: 0.0631 - val_mse: 0.0086\n",
      "Epoch 111/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9814 - loss: 0.0040 - mae: 0.0613 - mse: 0.0081 - val_accuracy: 0.9831 - val_loss: 0.0045 - val_mae: 0.0641 - val_mse: 0.0089\n",
      "Epoch 112/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.9807 - loss: 0.0041 - mae: 0.0608 - mse: 0.0081 - val_accuracy: 0.9834 - val_loss: 0.0042 - val_mae: 0.0618 - val_mse: 0.0084\n",
      "Epoch 113/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9815 - loss: 0.0039 - mae: 0.0594 - mse: 0.0077 - val_accuracy: 0.9834 - val_loss: 0.0042 - val_mae: 0.0623 - val_mse: 0.0084\n",
      "Epoch 114/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.9820 - loss: 0.0039 - mae: 0.0596 - mse: 0.0078 - val_accuracy: 0.9832 - val_loss: 0.0043 - val_mae: 0.0621 - val_mse: 0.0086\n",
      "Epoch 115/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9790 - loss: 0.0039 - mae: 0.0597 - mse: 0.0078 - val_accuracy: 0.9838 - val_loss: 0.0043 - val_mae: 0.0626 - val_mse: 0.0085\n",
      "Epoch 116/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.9806 - loss: 0.0039 - mae: 0.0595 - mse: 0.0077 - val_accuracy: 0.9853 - val_loss: 0.0044 - val_mae: 0.0645 - val_mse: 0.0088\n",
      "Epoch 117/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9812 - loss: 0.0039 - mae: 0.0591 - mse: 0.0077 - val_accuracy: 0.9839 - val_loss: 0.0042 - val_mae: 0.0613 - val_mse: 0.0083\n",
      "Epoch 118/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9820 - loss: 0.0038 - mae: 0.0587 - mse: 0.0076 - val_accuracy: 0.9811 - val_loss: 0.0043 - val_mae: 0.0633 - val_mse: 0.0087\n",
      "Epoch 119/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9798 - loss: 0.0040 - mae: 0.0604 - mse: 0.0081 - val_accuracy: 0.9825 - val_loss: 0.0042 - val_mae: 0.0619 - val_mse: 0.0084\n",
      "Epoch 120/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9822 - loss: 0.0039 - mae: 0.0598 - mse: 0.0078 - val_accuracy: 0.9836 - val_loss: 0.0042 - val_mae: 0.0621 - val_mse: 0.0085\n",
      "Epoch 121/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 63ms/step - accuracy: 0.9817 - loss: 0.0039 - mae: 0.0598 - mse: 0.0078 - val_accuracy: 0.9848 - val_loss: 0.0042 - val_mae: 0.0618 - val_mse: 0.0084\n",
      "Epoch 122/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 61ms/step - accuracy: 0.9821 - loss: 0.0039 - mae: 0.0593 - mse: 0.0078 - val_accuracy: 0.9822 - val_loss: 0.0042 - val_mae: 0.0617 - val_mse: 0.0083\n",
      "Epoch 123/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9832 - loss: 0.0038 - mae: 0.0592 - mse: 0.0077 - val_accuracy: 0.9836 - val_loss: 0.0043 - val_mae: 0.0639 - val_mse: 0.0087\n",
      "Epoch 124/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9820 - loss: 0.0038 - mae: 0.0595 - mse: 0.0077 - val_accuracy: 0.9849 - val_loss: 0.0042 - val_mae: 0.0623 - val_mse: 0.0084\n",
      "Epoch 125/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9826 - loss: 0.0037 - mae: 0.0588 - mse: 0.0075 - val_accuracy: 0.9831 - val_loss: 0.0043 - val_mae: 0.0633 - val_mse: 0.0085\n",
      "Epoch 126/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9795 - loss: 0.0037 - mae: 0.0586 - mse: 0.0075 - val_accuracy: 0.9845 - val_loss: 0.0044 - val_mae: 0.0644 - val_mse: 0.0089\n",
      "Epoch 127/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9825 - loss: 0.0038 - mae: 0.0592 - mse: 0.0077 - val_accuracy: 0.9836 - val_loss: 0.0041 - val_mae: 0.0618 - val_mse: 0.0083\n",
      "Epoch 128/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9804 - loss: 0.0037 - mae: 0.0585 - mse: 0.0075 - val_accuracy: 0.9839 - val_loss: 0.0041 - val_mae: 0.0609 - val_mse: 0.0082\n",
      "Epoch 129/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9821 - loss: 0.0037 - mae: 0.0583 - mse: 0.0075 - val_accuracy: 0.9835 - val_loss: 0.0044 - val_mae: 0.0642 - val_mse: 0.0088\n",
      "Epoch 130/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9817 - loss: 0.0037 - mae: 0.0589 - mse: 0.0074 - val_accuracy: 0.9851 - val_loss: 0.0043 - val_mae: 0.0628 - val_mse: 0.0085\n",
      "Epoch 131/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9814 - loss: 0.0038 - mae: 0.0588 - mse: 0.0076 - val_accuracy: 0.9849 - val_loss: 0.0042 - val_mae: 0.0613 - val_mse: 0.0084\n",
      "Epoch 132/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9814 - loss: 0.0038 - mae: 0.0586 - mse: 0.0076 - val_accuracy: 0.9838 - val_loss: 0.0043 - val_mae: 0.0623 - val_mse: 0.0085\n",
      "Epoch 133/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9799 - loss: 0.0038 - mae: 0.0588 - mse: 0.0076 - val_accuracy: 0.9839 - val_loss: 0.0042 - val_mae: 0.0614 - val_mse: 0.0084\n",
      "Epoch 134/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9821 - loss: 0.0038 - mae: 0.0583 - mse: 0.0075 - val_accuracy: 0.9836 - val_loss: 0.0043 - val_mae: 0.0624 - val_mse: 0.0085\n",
      "Epoch 135/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9826 - loss: 0.0037 - mae: 0.0583 - mse: 0.0074 - val_accuracy: 0.9849 - val_loss: 0.0042 - val_mae: 0.0614 - val_mse: 0.0084\n",
      "Epoch 136/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 60ms/step - accuracy: 0.9814 - loss: 0.0037 - mae: 0.0580 - mse: 0.0075 - val_accuracy: 0.9835 - val_loss: 0.0042 - val_mae: 0.0617 - val_mse: 0.0084\n",
      "Epoch 137/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9840 - loss: 0.0037 - mae: 0.0580 - mse: 0.0073 - val_accuracy: 0.9840 - val_loss: 0.0042 - val_mae: 0.0624 - val_mse: 0.0084\n",
      "Epoch 138/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 60ms/step - accuracy: 0.9788 - loss: 0.0038 - mae: 0.0589 - mse: 0.0075 - val_accuracy: 0.9839 - val_loss: 0.0041 - val_mae: 0.0609 - val_mse: 0.0083\n",
      "Epoch 139/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9807 - loss: 0.0037 - mae: 0.0585 - mse: 0.0075 - val_accuracy: 0.9825 - val_loss: 0.0042 - val_mae: 0.0614 - val_mse: 0.0084\n",
      "Epoch 140/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9805 - loss: 0.0037 - mae: 0.0583 - mse: 0.0074 - val_accuracy: 0.9841 - val_loss: 0.0043 - val_mae: 0.0625 - val_mse: 0.0085\n",
      "Epoch 141/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9810 - loss: 0.0037 - mae: 0.0581 - mse: 0.0073 - val_accuracy: 0.9830 - val_loss: 0.0043 - val_mae: 0.0634 - val_mse: 0.0087\n",
      "Epoch 142/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9810 - loss: 0.0038 - mae: 0.0587 - mse: 0.0075 - val_accuracy: 0.9841 - val_loss: 0.0044 - val_mae: 0.0638 - val_mse: 0.0088\n",
      "Epoch 143/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9814 - loss: 0.0037 - mae: 0.0580 - mse: 0.0073 - val_accuracy: 0.9831 - val_loss: 0.0044 - val_mae: 0.0637 - val_mse: 0.0088\n",
      "Epoch 144/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9782 - loss: 0.0038 - mae: 0.0591 - mse: 0.0076 - val_accuracy: 0.9835 - val_loss: 0.0043 - val_mae: 0.0624 - val_mse: 0.0085\n",
      "Epoch 145/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9809 - loss: 0.0037 - mae: 0.0580 - mse: 0.0074 - val_accuracy: 0.9838 - val_loss: 0.0043 - val_mae: 0.0633 - val_mse: 0.0086\n",
      "Epoch 146/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.9824 - loss: 0.0035 - mae: 0.0568 - mse: 0.0071 - val_accuracy: 0.9853 - val_loss: 0.0043 - val_mae: 0.0626 - val_mse: 0.0087\n",
      "Epoch 147/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9829 - loss: 0.0036 - mae: 0.0575 - mse: 0.0072 - val_accuracy: 0.9831 - val_loss: 0.0044 - val_mae: 0.0642 - val_mse: 0.0089\n",
      "Epoch 148/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9812 - loss: 0.0036 - mae: 0.0581 - mse: 0.0071 - val_accuracy: 0.9829 - val_loss: 0.0043 - val_mae: 0.0620 - val_mse: 0.0085\n",
      "Epoch 149/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9829 - loss: 0.0036 - mae: 0.0574 - mse: 0.0072 - val_accuracy: 0.9846 - val_loss: 0.0043 - val_mae: 0.0625 - val_mse: 0.0086\n",
      "Epoch 150/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9816 - loss: 0.0036 - mae: 0.0574 - mse: 0.0071 - val_accuracy: 0.9840 - val_loss: 0.0043 - val_mae: 0.0626 - val_mse: 0.0085\n",
      "Epoch 151/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9838 - loss: 0.0035 - mae: 0.0568 - mse: 0.0070 - val_accuracy: 0.9825 - val_loss: 0.0042 - val_mae: 0.0623 - val_mse: 0.0085\n",
      "Epoch 152/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9811 - loss: 0.0036 - mae: 0.0578 - mse: 0.0072 - val_accuracy: 0.9836 - val_loss: 0.0042 - val_mae: 0.0620 - val_mse: 0.0084\n",
      "Epoch 153/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9809 - loss: 0.0035 - mae: 0.0569 - mse: 0.0070 - val_accuracy: 0.9825 - val_loss: 0.0045 - val_mae: 0.0649 - val_mse: 0.0090\n",
      "Epoch 154/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.9830 - loss: 0.0036 - mae: 0.0574 - mse: 0.0072 - val_accuracy: 0.9836 - val_loss: 0.0044 - val_mae: 0.0637 - val_mse: 0.0088\n",
      "Epoch 155/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.9800 - loss: 0.0037 - mae: 0.0582 - mse: 0.0074 - val_accuracy: 0.9831 - val_loss: 0.0043 - val_mae: 0.0632 - val_mse: 0.0086\n",
      "Epoch 156/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.9807 - loss: 0.0036 - mae: 0.0576 - mse: 0.0072 - val_accuracy: 0.9834 - val_loss: 0.0043 - val_mae: 0.0628 - val_mse: 0.0086\n",
      "Epoch 157/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9827 - loss: 0.0036 - mae: 0.0574 - mse: 0.0071 - val_accuracy: 0.9853 - val_loss: 0.0044 - val_mae: 0.0638 - val_mse: 0.0087\n",
      "Epoch 158/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9824 - loss: 0.0036 - mae: 0.0578 - mse: 0.0072 - val_accuracy: 0.9841 - val_loss: 0.0043 - val_mae: 0.0627 - val_mse: 0.0086\n",
      "Epoch 159/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.9822 - loss: 0.0036 - mae: 0.0575 - mse: 0.0072 - val_accuracy: 0.9839 - val_loss: 0.0044 - val_mae: 0.0643 - val_mse: 0.0088\n",
      "Epoch 160/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9840 - loss: 0.0036 - mae: 0.0576 - mse: 0.0072 - val_accuracy: 0.9822 - val_loss: 0.0044 - val_mae: 0.0633 - val_mse: 0.0087\n",
      "Epoch 161/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.9824 - loss: 0.0034 - mae: 0.0560 - mse: 0.0068 - val_accuracy: 0.9831 - val_loss: 0.0042 - val_mae: 0.0626 - val_mse: 0.0085\n",
      "Epoch 162/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9818 - loss: 0.0035 - mae: 0.0567 - mse: 0.0070 - val_accuracy: 0.9826 - val_loss: 0.0044 - val_mae: 0.0638 - val_mse: 0.0088\n",
      "Epoch 163/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9826 - loss: 0.0035 - mae: 0.0574 - mse: 0.0070 - val_accuracy: 0.9832 - val_loss: 0.0044 - val_mae: 0.0646 - val_mse: 0.0089\n",
      "Epoch 164/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9801 - loss: 0.0036 - mae: 0.0578 - mse: 0.0071 - val_accuracy: 0.9841 - val_loss: 0.0042 - val_mae: 0.0623 - val_mse: 0.0085\n",
      "Epoch 165/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 60ms/step - accuracy: 0.9827 - loss: 0.0034 - mae: 0.0565 - mse: 0.0069 - val_accuracy: 0.9826 - val_loss: 0.0043 - val_mae: 0.0634 - val_mse: 0.0087\n",
      "Epoch 166/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9827 - loss: 0.0034 - mae: 0.0564 - mse: 0.0069 - val_accuracy: 0.9824 - val_loss: 0.0046 - val_mae: 0.0671 - val_mse: 0.0093\n",
      "Epoch 167/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.9812 - loss: 0.0035 - mae: 0.0581 - mse: 0.0071 - val_accuracy: 0.9824 - val_loss: 0.0046 - val_mae: 0.0654 - val_mse: 0.0091\n",
      "Epoch 168/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.9818 - loss: 0.0035 - mae: 0.0570 - mse: 0.0069 - val_accuracy: 0.9830 - val_loss: 0.0044 - val_mae: 0.0635 - val_mse: 0.0088\n",
      "Epoch 169/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9823 - loss: 0.0034 - mae: 0.0566 - mse: 0.0068 - val_accuracy: 0.9843 - val_loss: 0.0042 - val_mae: 0.0627 - val_mse: 0.0085\n",
      "Epoch 170/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9830 - loss: 0.0035 - mae: 0.0572 - mse: 0.0070 - val_accuracy: 0.9838 - val_loss: 0.0044 - val_mae: 0.0634 - val_mse: 0.0088\n",
      "Epoch 171/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9812 - loss: 0.0034 - mae: 0.0563 - mse: 0.0069 - val_accuracy: 0.9835 - val_loss: 0.0044 - val_mae: 0.0647 - val_mse: 0.0088\n",
      "Epoch 172/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.9823 - loss: 0.0034 - mae: 0.0564 - mse: 0.0069 - val_accuracy: 0.9836 - val_loss: 0.0044 - val_mae: 0.0630 - val_mse: 0.0087\n",
      "Epoch 173/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.9821 - loss: 0.0035 - mae: 0.0570 - mse: 0.0070 - val_accuracy: 0.9844 - val_loss: 0.0044 - val_mae: 0.0643 - val_mse: 0.0088\n",
      "Epoch 174/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9824 - loss: 0.0034 - mae: 0.0565 - mse: 0.0068 - val_accuracy: 0.9845 - val_loss: 0.0042 - val_mae: 0.0620 - val_mse: 0.0084\n",
      "Epoch 175/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.9831 - loss: 0.0034 - mae: 0.0567 - mse: 0.0068 - val_accuracy: 0.9841 - val_loss: 0.0043 - val_mae: 0.0632 - val_mse: 0.0087\n",
      "Epoch 176/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.9841 - loss: 0.0033 - mae: 0.0552 - mse: 0.0065 - val_accuracy: 0.9849 - val_loss: 0.0043 - val_mae: 0.0627 - val_mse: 0.0085\n",
      "Epoch 177/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.9828 - loss: 0.0033 - mae: 0.0559 - mse: 0.0067 - val_accuracy: 0.9840 - val_loss: 0.0042 - val_mae: 0.0621 - val_mse: 0.0085\n",
      "Epoch 178/200\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.9810 - loss: 0.0033 - mae: 0.0553 - mse: 0.0066 - val_accuracy: 0.9839 - val_loss: 0.0044 - val_mae: 0.0637 - val_mse: 0.0087\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9851 - loss: 0.0043 - mae: 0.0629 - mse: 0.0086\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.004361042287200689,\n",
       " 0.06371072679758072,\n",
       " 0.008722084574401379,\n",
       " 0.9838792085647583]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Define callbacks and fit the model\n",
    "log_dir = \"../logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=50)\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(schedule)\n",
    "\n",
    "model.fit(\n",
    "  x=x_train, \n",
    "  y=y_train,\n",
    "  epochs=200,\n",
    "  validation_data=(x_test, y_test),\n",
    "  callbacks=[tensorboard_callback, early_stopping,]) #Can add lr_scheduler\n",
    "\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## Save the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models/model_v4.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "## Save the model\n",
    "model.save('../models/model_v4.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
